# Hugging Face LLM inference example 

This is a simple example of how to use the [text-generation-inference](https://github.com/huggingface/text-generation-inference) library to deploy LLMs, like BLOOM, GPT-NeoX, FLAN-T5-XXL to Amaozn SageMaker.

## Requirements

- SageMaker compute quota for p4 instances

## Getting Started

Check out the [sagemaker-notebook](sagemaker-notebook.ipynb) for a step-by-step guide on how to deploy BLOOM to Amazon SageMaker.
